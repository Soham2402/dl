{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, Flatten\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "# Load the IMDB dataset\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=10000)\n",
        "\n",
        "# Pad the sequences\n",
        "max_length = 500\n",
        "X_train = pad_sequences(X_train, maxlen=max_length)\n",
        "X_test = pad_sequences(X_test, maxlen=max_length)\n",
        "\n",
        "# Define the model architecture\n",
        "model = Sequential([\n",
        "    Embedding(10000, 128, input_length=max_length),\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu', kernel_regularizer=l2(0.001)),\n",
        "    Dense(32, activation='relu', kernel_regularizer=l2(0.001)),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=5,\n",
        "    batch_size=64,\n",
        "    validation_data=(X_test, y_test)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqktYPV1Won1",
        "outputId": "f8685e37-f7a6-4657-9869-245d9c07ef59"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17464789/17464789 [==============================] - 0s 0us/step\n",
            "Epoch 1/5\n",
            "391/391 [==============================] - 52s 131ms/step - loss: 0.5947 - accuracy: 0.7478 - val_loss: 0.4376 - val_accuracy: 0.8728\n",
            "Epoch 2/5\n",
            "391/391 [==============================] - 51s 131ms/step - loss: 0.3048 - accuracy: 0.9415 - val_loss: 0.4954 - val_accuracy: 0.8568\n",
            "Epoch 3/5\n",
            "391/391 [==============================] - 52s 132ms/step - loss: 0.1578 - accuracy: 0.9861 - val_loss: 0.5238 - val_accuracy: 0.8598\n",
            "Epoch 4/5\n",
            "391/391 [==============================] - 52s 134ms/step - loss: 0.1056 - accuracy: 0.9952 - val_loss: 0.5683 - val_accuracy: 0.8599\n",
            "Epoch 5/5\n",
            "391/391 [==============================] - 53s 136ms/step - loss: 0.1121 - accuracy: 0.9953 - val_loss: 0.5781 - val_accuracy: 0.8599\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f1b19680cd0>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMLS36XgVZkf",
        "outputId": "0932b593-f011-4d7e-d52a-fb5639d5fe03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1641221/1641221 [==============================] - 0s 0us/step\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "Sample review text:\n",
            "? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? having been a godzilla fan for many years gamera was to me a cheap ? to capitalize on the success of ? 1 ? star attack of the monsters was for me at the time 1975 an almost painful viewing experience br br last weekend i attended the ? godzilla fest known as g fest where carl craig one of the stars of gamera vs made an appearance of course they featured this movie it was one of the most hilarious bad movies ever made of course you have to be in the right frame of mind to watch it in one scene for example the boy ? held prisoner on board the alien space craft manage to escape by distracting the not too bright aliens when they realize they ? been ? one of them says that's funny i think those kids ? to us not even plan nine from outer space can ? that kind of dialog br br this may not be godzilla or even gamera 3 but this one is a decent enough time ? if you watch it in the right frame of mind br br however if you want top quality ? entertainment check out the recently released gamera 3 br br rating 1 2 out of\n",
            "Predicted label: Negative\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Load the IMDB dataset\n",
        "word_index = imdb.get_word_index()\n",
        "\n",
        "# Reverse the word index to get the mapping from indices to words\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "\n",
        "# Function to decode the review text from the word indices\n",
        "def decode_review(review_indices):\n",
        "    words = [reverse_word_index.get(idx - 3, '?') for idx in review_indices]\n",
        "    return ' '.join(words)\n",
        "\n",
        "# Load a sample review from the test set\n",
        "sample_review_index = 42  # You can change this index to test different reviews\n",
        "sample_review = X_test[sample_review_index]\n",
        "\n",
        "# Pad the sample review to match the expected input shape\n",
        "sample_review = pad_sequences([sample_review], maxlen=max_length)\n",
        "\n",
        "# Make a prediction on the sample review\n",
        "prediction = model.predict(sample_review)\n",
        "prediction_label = 'Positive' if prediction > 0.5 else 'Negative'\n",
        "\n",
        "# Print the sample review text and the predicted label\n",
        "print('Sample review text:')\n",
        "print(decode_review(sample_review[0]))\n",
        "print(f'Predicted label: {prediction_label}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WREKusqNWnWk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}